{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mech0s/nodehenge/blob/main/doc2rdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2FMZ-cLUX2m"
      },
      "outputs": [],
      "source": [
        "scriptRevision = 17\n",
        "print (\"Revision\", scriptRevision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB-z2iTEUX2o"
      },
      "source": [
        "##  Install steps\n",
        "Need to re-run for each fresh google colab session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZHU52I0UX2q"
      },
      "outputs": [],
      "source": [
        "### commented out - rdfpandas not needed?\n",
        "###  %pip install rdfpandas\n",
        "#  %pip install pandas\n",
        "#  %pip install openpyxl\n",
        "%pip install rdflib\n",
        "%pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAwgZO9_i0fR"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN3cL_Osi0fR"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xqwx05JeLaP"
      },
      "outputs": [],
      "source": [
        "# file structure creation\n",
        "from pathlib import Path\n",
        "import os, shutil\n",
        "# create the folder structure in the colab session (colab does not pull this from github when opening the notebook)\n",
        "Path(\"gen\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"resource\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"publish/nodehenge.gov\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"publish/nodehenge.org\").mkdir(parents=True, exist_ok=True)\n",
        "# if accessible (not in colab) copy the ontology into the publish area\n",
        "if os.path.isfile(\"resource/ont.ttl\") : shutil.copy(\"resource/ont.ttl\",\"publish/nodehenge.org/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqc52ohYUX2q"
      },
      "source": [
        "##   Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8S3Lkr9UX2q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SxFF3EBUX2q"
      },
      "source": [
        "### Optional    google  colab   enhancements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3A_QUmxUX2r"
      },
      "outputs": [],
      "source": [
        "#optional\n",
        "if 'COLAB_JUPYTER_TOKEN' in os.environ:\n",
        "  from google.colab import data_table\n",
        "  data_table.enable_dataframe_formatter()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1sXQLGUUX2r"
      },
      "source": [
        "## Source Data Read/Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtU0oP9UX2r"
      },
      "source": [
        "### Read dodcio DevSecOpsActivitesToolsGuidebookTables.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM3cl4JMi0fV"
      },
      "outputs": [],
      "source": [
        "def cleanCamel(r):\n",
        "  r = re.sub('\\W|^(?=\\d)','_', r) ## cleans to make a valid identifier\n",
        "  r = re.sub(r\"(_|-|\\n|!)+\", \" \", r).title().replace(\" \", \"\")  ## turns to camel-case\n",
        "  return ''.join([r[0].lower(), r[1:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAK5AP5LUX2r"
      },
      "outputs": [],
      "source": [
        "sourceURI = \"https://dodcio.defense.gov/Portals/0/Documents/Library/DevSecOpsActivitesToolsGuidebookTables.xlsx\"\n",
        "xls = pd.ExcelFile(sourceURI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjZeS1j7UX2r"
      },
      "source": [
        "### Setup fixed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwZO0RlBUX2s"
      },
      "outputs": [],
      "source": [
        "phaseNames = [ 'Plan',\n",
        " 'Develop',\n",
        " 'Build',\n",
        " 'Test',\n",
        " 'Release',\n",
        " 'Deliver',\n",
        " 'Deploy',\n",
        " 'Operate',\n",
        " 'Monitor',\n",
        " 'Feedback']\n",
        "phaseIDs = list(map(cleanCamel, phaseNames))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvkNyFwTUX2s"
      },
      "source": [
        "##  Build phaseActivityDataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ_749-dUX2s"
      },
      "source": [
        "One named worksheet per phase: Pull these into a list of DataFrames, adjusting column names to create valid identifiers. Turn NaN entries into blank strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwYBj7y5UX2s"
      },
      "outputs": [],
      "source": [
        "phaseDataList = []\n",
        "phaseOrder = 0\n",
        "for phName in phaseNames:\n",
        "  df = pd.read_excel(xls,phName)\n",
        "  df = df.rename(columns={\"Activities\":\"Activity\",\n",
        "                     \"Security / Testing / CM\": \"SecurityTestingCM\",\n",
        "                     \"Tool Dependencies\": \"ToolDependency\",\n",
        "                     \"Tool Dependency\": \"ToolDependency\"\n",
        "                     })\n",
        "  # add Phase and order columns - alternative avoid tricky MultiIndex when concatening below\n",
        "  df[\"Phase\"] = phName\n",
        "  df[\"PhaseOrder\"] = phaseOrder\n",
        "  df[\"OrderInPhase\"] = df.index\n",
        "  phaseOrder+=1\n",
        "  #\n",
        "  phaseDataList.append(df.replace(np.nan, \"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG1YtjvbUX2s"
      },
      "source": [
        "phaseDataList : list of dataframes :- concatenate into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A4uBZcni0fZ"
      },
      "outputs": [],
      "source": [
        "phaseActivityDataFrame = pd.concat(phaseDataList)\n",
        "phaseActivityDataFrame.reset_index(drop=True, inplace=True)\n",
        "# MultiIndex example: phaseActivityDataFrame = pd.concat(phaseDataList,keys=phaseNames, names=[\"Phase\",\"IDinPhase\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1otTzdkdi0fZ"
      },
      "outputs": [],
      "source": [
        "phaseActivityDataFrame[\"ActivityIdentifier\"] = phaseActivityDataFrame[\"Activity\"].apply( cleanCamel )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moFhiHyMi0fZ"
      },
      "outputs": [],
      "source": [
        "# just inspecting as json (enables processing using GPT3/4 possibilities)\n",
        "phaseActivityDataFrame.to_json(orient='table')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdhybdnYUX2t"
      },
      "outputs": [],
      "source": [
        "phaseActivityDataFrame.rename(columns={\"ToolDependency\":\"ToolDependenciesText\", \"Inputs\":\"InputsText\", \"Outputs\":\"OutputsText\"},inplace=True)\n",
        "## prepare empty lists to accept values parsed from text fields\n",
        "phaseActivityDataFrame[\"ToolsList\"]=[[] for _ in range(len(phaseActivityDataFrame))]\n",
        "phaseActivityDataFrame[\"InputsList\"]=[[] for _ in range(len(phaseActivityDataFrame))]\n",
        "phaseActivityDataFrame[\"OutputsList\"]=[[] for _ in range(len(phaseActivityDataFrame))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_FjSUDIi0fa"
      },
      "outputs": [],
      "source": [
        "# just checking sheet names\n",
        "xls.sheet_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r_wKzoxi0fa"
      },
      "outputs": [],
      "source": [
        "toolsDataFrame = pd.read_excel(xls, \"Tools\")\n",
        "toolsDataFrame.replace(np.nan, \"\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9gMgnpGi0fb"
      },
      "outputs": [],
      "source": [
        "toolsDataFrame.rename(columns={ \"Inputs\":\"InputsText\", \"Outputs\":\"OutputsText\"},inplace=True)\n",
        "toolsDataFrame[\"InputsList\"]=[[] for _ in range(len(toolsDataFrame))]\n",
        "toolsDataFrame[\"OutputsList\"]=[[] for _ in range(len(toolsDataFrame))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdSjknti0fb"
      },
      "source": [
        "### Dataframe select, filter, order examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQpCOIyPi0fb"
      },
      "outputs": [],
      "source": [
        "### Dataframe slicing examples\n",
        "phaseActivityDataFrame.iloc[3:39]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9qpLPL3i0fc"
      },
      "outputs": [],
      "source": [
        "### Dataframe ordering and filtering examples\n",
        "phaseActivityDataFrame.sort_values([\"PhaseOrder\",\"OrderInPhase\"])[phaseActivityDataFrame[\"Phase\"]>=\"Plan\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2zKaciRi0fc"
      },
      "outputs": [],
      "source": [
        "### Dataframe selection examples\n",
        "phaseActivityDataFrame[[\"Phase\",\"Baseline\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMxwLnasi0fc"
      },
      "outputs": [],
      "source": [
        "### access to lists within cells\n",
        "toolsDataFrame.iloc[0].InputsList.append(123)\n",
        "toolsDataFrame.iloc[0].InputsList.clear()\n",
        "toolsDataFrame.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB6xKthCi0fd"
      },
      "source": [
        "### Parse out text cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiM3HKAUi0fd"
      },
      "outputs": [],
      "source": [
        "#helper function - check what text isn't being extracted from a string during parsing\n",
        "def remaining_text(txt, strs):\n",
        "    rem = txt\n",
        "    for s in strs:\n",
        "        rem = rem.replace(s,'')\n",
        "\n",
        "    return rem.replace(\"\\n\",\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-B96jb9i0fe"
      },
      "source": [
        "### Cleansing of text list cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stash uncleansed data to allow repeated, perhaps destructive cleansing attempts below\n",
        "toolsDataFramePreMods = toolsDataFrame.copy()\n",
        "phaseActivityDataFramePreMods = phaseActivityDataFrame.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47OmY4n_i0fe"
      },
      "outputs": [],
      "source": [
        "# start (again) from stashed data\n",
        "toolsDataFrame = toolsDataFramePreMods.copy()\n",
        "phaseActivityDataFrame = phaseActivityDataFramePreMods.copy()\n",
        "\n",
        "inputOutputReplaces ={    # \"is real\" phrase addition leads NLP into treating elements a noun chunk\n",
        "           \"Change management\" : \"Change-management\" ,\n",
        "           \"IT infrastructure asset\" : \"IT-infrastructure-asset\",\n",
        "            \"Artifacts (Infrastructure as Code)\" : \"IAC Artifacts,\",\n",
        "            \"Infrastructure as Code\" : \"IAC is real\",\n",
        "            \"Infrastructure as code\" : \"IAC is real\",\n",
        "            \"NIST 800-53 RMF Control Implementations\" :\"NIST80053RMFControl-Implementation,\",\n",
        "            \"FIPS 199 system categorization\" : \"FIPS-199-system-categorization,\",\n",
        "            \"Stakeholder inputs or feedback\" : \"Stakeholder-input, Stakeholder feedback\",\n",
        "            \"Requirements database or documents\" : \"Requirements database, Requirements document\",\n",
        "            \"Test environment applications and infrastructure\" : \"Test environment application, Test environment infrastructure\",\n",
        "            \"Developer coding and appropriate unit, integration, etc. testing input\" : \"Code-Development input, Unit test input, Integration test input, Other test input\",\n",
        "            \"- Review Comments\" : \"Review-Comment,\",\n",
        "            \"- Source Code Weakness Findings\" : \"Source Code Weakness Findings,\",\n",
        "            \"- Version-Controlled Source Code\" :\"Version-Controlled Source Code,\",\n",
        "            \"- Security Findings and Warnings\" : \"Security Findings, Security Warning,\",\n",
        "            'Technical feedback as to “is the system built right” and operational feedback as to “was the right system built”' : \"Technical feedback. Operational feedback.\",\n",
        "            \"Database traffic, event, and activities\" : \"Database traffic. Database events. Database activities.\",\n",
        "            \"Artifacts in the repository;\" : \"Artifacts.\",\n",
        "            \"Requirements documents and/or database;\" : \"Requirements documents. Requirements database.\",\n",
        "            \"Requirement documents and/or database\" : \"Requirements documents. Requirements database\",\n",
        "            \"Requirements database or documents\" : \"Requirements documents. Requirements database\",\n",
        "            \"Software Factory controls\" : \"Software-Factory controls are real.\",\n",
        "            \"Software Bill of Materials\" : \"SBOM\",\n",
        "            \"Functional and non-functional regression test cases\" : \"Regression-test cases.\",\n",
        "            \"and the software system\" : \". Software system\",\n",
        "            \"\\nThe software system\" : \". Software system\",\n",
        "            \"\\nDatabase artifacts;\" : \". Database artifacts are real .\",\n",
        "            \"\\nRelease notes\" : \". Release notes are real.\",\n",
        "            \"APIs for integrated systems\" : \"APIs are real\",\n",
        "            \"\\nDependency checking report\" : \". Dependency-checking report is real\",\n",
        "            \"individual software unit under test (a function, method or an interface)\" : \"software unit\",\n",
        "            \"expected output data\" : \"expected-output-data is real\",\n",
        "            \"Updates to the Product Backlog\" : \"Product-backlog updates\",\n",
        "            \"Performance KPI measures\" : \"KPI-measures are real\",\n",
        "            \"and remediation reports\" : \". Remediation reports are real\",\n",
        "            \"Point-in-time recovered file\" : \"Recovered file\",\n",
        "            \"Reports of observed performance\" : \"Observed-performance reports\",\n",
        "            \"Reports of test results\" : \"Test-result Reports\",\n",
        "            \"New release in the artifact repository\" : \"Release-To-Repo is real\",\n",
        "            \"\\nPush go/no-go decision\" : \". Push go/no-go decision\",\n",
        "            \"go / no-go decision; \\nArtifacts are tagged with release tag if go decision is made\" : \"Go/no-go decision is real. Artifacts-release-tag is real\",\n",
        "            \"Artifacts in all regional artifact repositories\" : \"Replicated Artifacts\",\n",
        "            \"Test report to determine whether the individual software unit performs as designed.\" : \"Test report is real\",\n",
        "            \"test scripts, the software units under test, test input data, and expected output data\" : \"test scripts. Software-units under test. Test-input data. Expected-output data\",\n",
        "            \"- Auto generated Application Programming Interface (API) documentation\" : \"Generated-API documentation\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "\n",
        "            \"Aggregated filtered logs from the Log Aggregator\" : \"Aggregated filtered logs are real\",\n",
        "            \"Vulnerability and non-compliance findings from Information Security Continuous Monitoring\" : \"Vulnerability findings . non-compliance findings\",\n",
        "            \"Recommendations from Information Security Continuous Monitoring\" : \"information security recommendations\",\n",
        "            \"Performance statistics from Operations Monitoring\" : \"Performance statistics\",\n",
        "            \"Performance alerts from Operations Monitoring\" : \"Performance-alert are real\",\n",
        "            \"IT assets (applications, software licenses, libraries, operating systems, and versioning information)\" : \"IT-infrastructure-asset\",\n",
        "            \"Access to the backup source\" : \"backup-source access\",\n",
        "            \"Source code under version control\" : \"Version-Controlled Source Code\",\n",
        "            \"IT hardware and software components information\" : \"IT hardware information . Software component information is real\",\n",
        "            \"Everything as Code\" : \"EAC is real\", \n",
        "            \"Cyber threat condition feeds\" : \"Cyber-threat-condition feed\",\n",
        "            \"Running status and events\" : \"Database status . Database-event\",\n",
        "            \"BOM, including:\\nDependency list\\nLicensing\" : \"BOM, including:\\nDependency list\\n Licensing is real\",\n",
        "            \"Running software application\" : \"running software application is real\",\n",
        "            \"Fuzz inputs\" : \"Fuzz inputs are real\",\n",
        "            \"Developer coding input\" : \"Code-Development input\",\n",
        "            \"Running application and operating systems\" : \"Running software application is real . Running operating system is real .\",\n",
        "            \"Root cause analysis\" : \"Root-cause analysis\",\n",
        "            \"Root cause analysis\" : \"Root-cause analysis\",\n",
        "            \"Feature/change request\" : \"Feature request . change request\",\n",
        "            \"security audit logs\" : \"security audit logs are real\",\n",
        "            \"Event Logs\" : \"Event Log is real\",\n",
        "            \"Event logs\" : \"Event Log is real\",\n",
        "            \"All user, network, application, and data activities\" : \"user activities. network activities. application activities. data activities\",\n",
        "            \"All operational monitoring status, alerts\" : \"Operational-monitoring status, Operational-monitoring alert\",\n",
        "            \"Performance KPI\" : \"KPI is real. \",\n",
        "            \"Service Level Agreement (SLA)\" : \"SLA is real.\",\n",
        "            \"Service Level Agreements\" : \"SLA is real.\",\n",
        "            \"Software instances\" : \"Software instances are real\",\n",
        "\n",
        "            \"\\nSystem VM or container snapshot\" : \"\\nSystem VM snapshot . container snapshot\",\n",
        "            \"Binary artifacts stored in the Artifact repository\" : \"Binary artifacts\",\n",
        "            \"code comments\" : \"code comments are real\",\n",
        "            \"Compliance reports\" : \"Compliance reports are real\",\n",
        "            \"Recommend changes in CSRP\" : \"CSRP-change recommendations\",\n",
        "            \"Audit logs;\" : \"Audit logs are real .\",\n",
        "            \"Recommended mitigation actions\" : \". Mitigation recommendations.\",\n",
        "            \"Dynamic code scan report \" : \"Dynamic-code-scan report.\",\n",
        "            \"and recommended mitigation\" : \". Mitigation recommendations.\",\n",
        "            \"Issue resolution tracking history\" : \"Issue-resolution-tracking history\",\n",
        "            \"Remediation report and log\" : \"Remediation report . Remediation log is real\",\n",
        "            \"Performance alerts\" : \"Performance alerts are real\",\n",
        "            \"Release package with checksum and digital signature (a bundle of artifacts, such as a self-extracting software installer, or a tar file, etc.)\" : \"Release package is real\",\n",
        "            \"Security findings and warnings\" : \"Security findings. Security warnings\",\n",
        "            \"Static code scan report\" : \"Static-code-scan report\",\n",
        "            \"The percentage of code that is exercised by the tests.\" : \"Code-Test-Coverage-Pct is real\",\n",
        "            \"Input data for the system under test\" : \"Test data\",\n",
        "            \"Test results statistics\" : \"Test-result statistics\",\n",
        "            \"Running VM\" : \"Running-VM is real\",\n",
        "\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "\n",
        "}\n",
        "toolsDataFrame[\"InputsTextNlpPrepped\"] = toolsDataFrame.InputsText\n",
        "toolsDataFrame[\"OutputsTextNlpPrepped\"] = toolsDataFrame.OutputsText\n",
        "phaseActivityDataFrame[\"InputsTextNlpPrepped\"] = phaseActivityDataFrame.InputsText\n",
        "phaseActivityDataFrame[\"OutputsTextNlpPrepped\"] = phaseActivityDataFrame.OutputsText\n",
        "phaseActivityDataFrame[\"ToolsTextNlpPrepped\"] = phaseActivityDataFrame.ToolDependenciesText\n",
        "\n",
        "for pair in inputOutputReplaces.items():\n",
        "    toolsDataFrame.InputsTextNlpPrepped = toolsDataFrame.apply(lambda x : x.InputsTextNlpPrepped.replace(pair[0], pair[1]), axis='columns')\n",
        "    toolsDataFrame.OutputsTextNlpPrepped = toolsDataFrame.apply(lambda x : x.OutputsTextNlpPrepped.replace(pair[0], pair[1]), axis='columns')\n",
        "    phaseActivityDataFrame.InputsTextNlpPrepped = phaseActivityDataFrame.apply(lambda x : x.InputsTextNlpPrepped.replace(pair[0], pair[1]), axis='columns')\n",
        "    phaseActivityDataFrame.OutputsTextNlpPrepped = phaseActivityDataFrame.apply(lambda x : x.OutputsTextNlpPrepped.replace(pair[0], pair[1]), axis='columns')\n",
        "\n",
        "toolReplaces = {\n",
        "            \"Monitoring tool suite\" : \"Monitoring-tool suite\",\n",
        "            \"Test tool suite\" : \"Test-tool suite\",\n",
        "            \"Log aggregator\" : \"Log-aggregator\",\n",
        "            \"Log analysis & auditing\" : \"Log-analysis, Log-auditing, \",\n",
        "            \"Logging\" : \"Logging-tool\",\n",
        "            \"Logging-tool tool\" : \"Logging-tool\",\n",
        "            \"Track test and security scan results\" : \"test-and-scan tracker\",\n",
        "            \"\\nAlerting and notification\" : \";. Alerting-notification system. \",\n",
        "            \"\\nIssue tracking system\" : \";. Issue-tracking system;\",\n",
        "            \"Compliance as Code\" : \"Compliance-as-Code is real\",\n",
        "            \"Non-security compliance scan\" : \"Non-security-compliance-scan tool\",\n",
        "            \"Artifacts repositories (release, regional)\" : \"Artifacts repository\",\n",
        "            \"Vulnerability findings;\\nRecommended mitigation actions\" : \"\",\n",
        "            \"Test results documenting the performance of the system.\" : \"\",\n",
        "            \"Test results documenting the functioning of the system.\" : \"\",\n",
        "            \"Test report documenting the performance of the integrated unit.\" : \"\",\n",
        "            \"Dependency checking / BOM checking tool\" : \"Dependency-BOM-checking tool\",\n",
        "            \"IDE or document editor or build tool\" : \"IDE is real. Document editor. Build tool.\",\n",
        "            \"IDE or tools come with the database software\" : \"IDE is real. Database-tools are real.\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "            \"\" : \"\",\n",
        "}\n",
        "for pair in toolReplaces.items():\n",
        "    toolsDataFrame.Tool = toolsDataFrame.apply(lambda x : x.Tool.replace(pair[0], pair[1]), axis='columns')\n",
        "    phaseActivityDataFrame.ToolsTextNlpPrepped = phaseActivityDataFrame.apply(lambda x : x.ToolsTextNlpPrepped.replace(pair[0], pair[1]), axis='columns')\n",
        "\n",
        "\n",
        "# nlp extraction of noun phrases\n",
        "toolsDataFrame.InputsList = toolsDataFrame.apply(lambda x :  [chunk.text for chunk in nlp(x.InputsTextNlpPrepped.replace(\"\\n\",\" . \")).noun_chunks], axis='columns') # period better than \\n as separator between noun chunks\n",
        "toolsDataFrame.OutputsList = toolsDataFrame.apply(lambda x :  [chunk.text for chunk in nlp(x.OutputsTextNlpPrepped.replace(\"\\n\",\" . \")).noun_chunks], axis='columns')\n",
        "phaseActivityDataFrame.InputsList = phaseActivityDataFrame.apply(lambda x :  [chunk.text for chunk in nlp(x.InputsTextNlpPrepped.replace(\"\\n\",\" . \")).noun_chunks], axis='columns')\n",
        "phaseActivityDataFrame.OutputsList = phaseActivityDataFrame.apply(lambda x :  [chunk.text for chunk in nlp(x.OutputsTextNlpPrepped.replace(\"\\n\",\" . \")).noun_chunks], axis='columns')\n",
        "phaseActivityDataFrame.ToolsList = phaseActivityDataFrame.apply(lambda x :  [chunk.text for chunk in nlp(x.ToolsTextNlpPrepped.replace(\"\\n\",\" . \")).noun_chunks], axis='columns')\n",
        "\n",
        "# text left behind\n",
        "toolsDataFrame['InputsTextRemainder'] = toolsDataFrame.apply(lambda x : remaining_text(x.InputsText, x.InputsList) , axis='columns')\n",
        "toolsDataFrame['OutputsTextRemainder'] = toolsDataFrame.apply(lambda x : remaining_text(x.OutputsText, x.OutputsList) , axis='columns')\n",
        "phaseActivityDataFrame['InputsTextRemainder'] = phaseActivityDataFrame.apply(lambda x : remaining_text(x.InputsText, x.InputsList) , axis='columns')\n",
        "phaseActivityDataFrame['OutputsTextRemainder'] = phaseActivityDataFrame.apply(lambda x : remaining_text(x.OutputsText, x.OutputsList) , axis='columns')\n",
        "phaseActivityDataFrame['ToolsTextRemainder'] = phaseActivityDataFrame.apply(lambda x : remaining_text(x.ToolDependenciesText, x.ToolsList) , axis='columns')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvrP698mi0ff"
      },
      "source": [
        "### Cleansed - Now turn item names into identifiers - camelCase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztbGyeiai0ff"
      },
      "outputs": [],
      "source": [
        "toolsDataFrame[\"ToolIdentifier\"]=toolsDataFrame[\"Tool\"].apply( cleanCamel )\n",
        "toolsDataFrame.InputsList = toolsDataFrame.apply(lambda x : [ cleanCamel(y) for y in x.InputsList ], axis='columns' )\n",
        "toolsDataFrame.OutputsList = toolsDataFrame.apply(lambda x : [ cleanCamel(y) for y in x.OutputsList ], axis='columns' )\n",
        "phaseActivityDataFrame.InputsList = phaseActivityDataFrame.apply(lambda x : [ cleanCamel(y) for y in x.InputsList ], axis='columns' )\n",
        "phaseActivityDataFrame.OutputsList = phaseActivityDataFrame.apply(lambda x : [ cleanCamel(y) for y in x.OutputsList ], axis='columns' )\n",
        "phaseActivityDataFrame.ToolsList = phaseActivityDataFrame.apply(lambda x : [ cleanCamel(y) for y in x.ToolsList ], axis='columns' )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspection post-cleasning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raZEw8sIi0ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "#filtered column view to aid visual inspection post-cleansing\n",
        "checkToolInputs = toolsDataFrame[[\"Tool\",\"InputsText\",\"InputsList\",\"InputsTextRemainder\", \"InputsTextNlpPrepped\",]]\n",
        "checkToolOutputs = toolsDataFrame[[\"Tool\",\"OutputsText\",\"OutputsList\",\"OutputsTextRemainder\", \"OutputsTextNlpPrepped\"]]\n",
        "checkPAInputs = phaseActivityDataFrame[[\"Phase\",\"Activity\",\"InputsText\",\"InputsList\",\"InputsTextRemainder\", \"InputsTextNlpPrepped\"]]\n",
        "checkPAOutputs = phaseActivityDataFrame[[\"Phase\",\"Activity\",\"OutputsText\",\"OutputsList\",\"OutputsTextRemainder\", \"OutputsTextNlpPrepped\"]]\n",
        "checkPATools = phaseActivityDataFrame[[\"Phase\",\"Activity\",\"ToolDependenciesText\",\"ToolsList\",\"ToolsTextRemainder\", \"ToolsTextNlpPrepped\"]]\n",
        "\n",
        "## uncomment a line to inspect cleansing results\n",
        "\n",
        "#json.loads(checkToolInputs.to_json(orient='table'))\n",
        "#json.loads(checkToolOutputs.to_json(orient='table'))\n",
        "#json.loads(checkPAInputs.to_json(orient='table'))\n",
        "#json.loads(checkPAOutputs.to_json(orient='table'))\n",
        "#json.loads(checkPATools.to_json(orient='table'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Olgs1Ci0fg"
      },
      "source": [
        "## TODO : Other sheets / regions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rEjOmS4i0fy"
      },
      "source": [
        "# RDF creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RDHGIQNi0fz"
      },
      "outputs": [],
      "source": [
        "from rdflib import Graph, Namespace, URIRef, Literal, BNode\n",
        "from rdflib.namespace import SKOS, RDF, RDFS, XSD, NamespaceManager, DCTERMS # DC, DOAP, FOAF, VOID, XMLNS\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNMX83NFjQbO"
      },
      "outputs": [],
      "source": [
        "# setup namespaces\n",
        "ONT = Namespace(\"http://nodehenge.org/ont#\")\n",
        "INST = Namespace(\"http://nodehenge.org/inst#\")\n",
        "PHASE = Namespace(\"http://nodehenge.org/inst/phase#\")\n",
        "TOOL = Namespace(\"http://nodehenge.org/inst/tool#\")\n",
        "ACT = Namespace(\"http://nodehenge.org/inst/activity#\")\n",
        "ART = Namespace(\"http://nodehenge.org/inst/artifact#\")\n",
        "# create graph and bind namespaces\n",
        "def newNodehengeGraph():\n",
        "  g = Graph() ###base=\"http://nodehenge.org/inst/\")\n",
        "  g.bind(\"rdf\", RDF)\n",
        "  g.bind(\"rdfs\", RDFS)\n",
        "  g.bind(\"skos\", SKOS)\n",
        "  g.bind(\"xsd\", XSD)\n",
        "  g.bind(\"ont\", ONT)\n",
        "  g.bind(\"inst\", INST)\n",
        "  g.bind(\"phase\", PHASE)\n",
        "  g.bind(\"tool\", TOOL)\n",
        "  g.bind(\"act\", ACT)\n",
        "  g.bind(\"art\", ART)\n",
        "  # g.parse(\"resource/ont.ttl\")  ## optional actually\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvqCwXBHi0fz"
      },
      "outputs": [],
      "source": [
        "# populate the top level INST namespace\n",
        "gTopLevel = newNodehengeGraph()\n",
        "gTopLevel.add ((INST.dodDsopScheme, RDF.type, SKOS.ConceptScheme ))\n",
        "gTopLevel.add ((INST.dodDsopScheme, DCTERMS.title, Literal(\"DoD DevSecOps Abstract Phase Activites and Tools Scheme\") ))\n",
        "gTopLevel.add ((INST.dodDsopScheme, DCTERMS.source, URIRef(sourceURI) ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pula_a57i0f0"
      },
      "outputs": [],
      "source": [
        "#populate the PHASE namespace\n",
        "gPhases = newNodehengeGraph()\n",
        "orderedPhaseBNodes = dict([(ph, BNode()) for ph in phaseIDs ])\n",
        "gPhases.add ((PHASE.phasing, RDF.type, SKOS.OrderedCollection))\n",
        "gPhases.add ((PHASE.phasing, SKOS.inScheme, INST.dodDsopScheme))\n",
        "gPhases.add ((PHASE.phasing, SKOS.memberList, orderedPhaseBNodes[phaseIDs[0]]))\n",
        "sideEffectTraversePhases = [ (\n",
        "    gPhases.add((\n",
        "        PHASE[current], RDF.type, ONT.Phase\n",
        "    )),\n",
        "    gPhases.add ((\n",
        "        PHASE[current], SKOS.inScheme, INST.dodDsopScheme\n",
        "    )),\n",
        "    gPhases.add((\n",
        "        PHASE[current], RDF.type, SKOS.Concept\n",
        "    )),\n",
        "    gPhases.add((\n",
        "        PHASE[current], SKOS.prefLabel, Literal(currentName)\n",
        "    )),\n",
        "    gPhases.add((\n",
        "        orderedPhaseBNodes[current], RDF.first, PHASE[current]    #list head\n",
        "    )),\n",
        "    gPhases.add((\n",
        "        orderedPhaseBNodes[current], RDF.rest , orderedPhaseBNodes[next] if next != None else RDF.nil\n",
        "    )),\n",
        "    )\n",
        "    for current, currentName, next in zip( phaseIDs, phaseNames , phaseIDs[1:]+[None]) ] # Traverse : zip current with next phase, until next is None. Allows for linked list creation\n",
        "\n",
        "print(gPhases.serialize(format=\"turtle\",destination=\"gen/phases.ttl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW-WSsZgi0f1"
      },
      "source": [
        "### Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWjqv0J0i0f1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "gToolsArts = newNodehengeGraph()\n",
        "toolsDataFrame.apply( lambda row :\n",
        "    (\n",
        "        gToolsArts.add((\n",
        "            TOOL[row.ToolIdentifier], RDF.type, ONT.AbstractTool\n",
        "        )),\n",
        "        gToolsArts.add((\n",
        "            TOOL[row.ToolIdentifier], RDF.type, SKOS.Concept\n",
        "        )),\n",
        "        gToolsArts.add ((\n",
        "            TOOL[row.ToolIdentifier], SKOS.inScheme, INST.dodDsopScheme\n",
        "        )),\n",
        "        gToolsArts.add((\n",
        "            TOOL[row.ToolIdentifier], SKOS.prefLabel, Literal(row.Tool)\n",
        "        )),\n",
        "        gToolsArts.add((\n",
        "            TOOL[row.ToolIdentifier], SKOS.definition, Literal(row.Benefits)\n",
        "        )),\n",
        "        gToolsArts.add((\n",
        "            TOOL[row.ToolIdentifier], SKOS.scopeNote, Literal(row.Features)\n",
        "        )),\n",
        "        [ ( gToolsArts.add(( ART[item], RDF.type, ONT.AbstractArtifact )),\n",
        "            gToolsArts.add(( ART[item], RDF.type, SKOS.Concept )),\n",
        "            gToolsArts.add(( ART[item], SKOS.inScheme, INST.dodDsopScheme )),\n",
        "            gToolsArts.add(( TOOL[row.ToolIdentifier], ONT.input, ART[item] )),\n",
        "            gToolsArts.add(( ART[item], ONT.input, TOOL[row.ToolIdentifier] )),\n",
        "            ) for item in row.InputsList ],\n",
        "        [ ( gToolsArts.add(( ART[item], RDF.type, ONT.AbstractArtifact )),\n",
        "            gToolsArts.add(( ART[item], RDF.type, SKOS.Concept )),\n",
        "            gToolsArts.add(( ART[item], SKOS.inScheme, INST.dodDsopScheme )),\n",
        "            gToolsArts.add(( TOOL[row.ToolIdentifier], ONT.output, ART[item] )),\n",
        "            gToolsArts.add(( ART[item], ONT.output, TOOL[row.ToolIdentifier] )),\n",
        "            ) for item in row.OutputsList ],\n",
        "    )\n",
        "    , axis='columns' )\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSSlmrYci0f3"
      },
      "outputs": [],
      "source": [
        "gPhaseActsArts = newNodehengeGraph()\n",
        "phaseActivityDataFrame.apply( lambda row :\n",
        "    (\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], RDF.type, ONT.AbstractActivity\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], RDF.type, SKOS.Concept\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.inScheme, INST.dodDsopScheme\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.prefLabel, Literal(row.Activity)\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.definition, Literal(row.Description)\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.scopeNote, Literal(\"Baseline: \" + row.Baseline )\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.scopeNote, Literal(\"Relevance: \" + row.SecurityTestingCM )\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.scopeNote, Literal(\"SSDF: \" + row.SSDF )\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], SKOS.editorialNote, Literal(\"skos:scopeNote currently holding three fields. Could normalize\")\n",
        "        )),\n",
        "        [ ( gPhaseActsArts.add(( ART[item], RDF.type, ONT.AbstractArtifact )),\n",
        "            gPhaseActsArts.add(( ART[item], RDF.type, SKOS.Concept )),\n",
        "            gPhaseActsArts.add(( ART[item], SKOS.inScheme, INST.dodDsopScheme )),\n",
        "            gPhaseActsArts.add(( ACT[row.ActivityIdentifier], ONT.input, ART[item] )),\n",
        "            gPhaseActsArts.add(( ART[item], ONT.input, ACT[row.ActivityIdentifier] )),\n",
        "            ) for item in row.InputsList ],\n",
        "        [ ( gPhaseActsArts.add(( ART[item], RDF.type, ONT.AbstractArtifact )),\n",
        "            gPhaseActsArts.add(( ART[item], RDF.type, SKOS.Concept )),\n",
        "            gPhaseActsArts.add(( ART[item], SKOS.inScheme, INST.dodDsopScheme )),\n",
        "            gPhaseActsArts.add(( ACT[row.ActivityIdentifier], ONT.output, ART[item] )),\n",
        "            gPhaseActsArts.add(( ART[item], ONT.output, ACT[row.ActivityIdentifier] )),\n",
        "            ) for item in row.OutputsList ],\n",
        "        [ ( gPhaseActsArts.add(( TOOL[item], RDF.type, TOOL.AbstractTool )),\n",
        "            gPhaseActsArts.add(( TOOL[item], RDF.type, SKOS.Concept )),\n",
        "            gPhaseActsArts.add(( TOOL[item], SKOS.inScheme, INST.dodDsopScheme )),\n",
        "            gPhaseActsArts.add(( ACT[row.ActivityIdentifier], ONT.activityTool, TOOL[item] )),\n",
        "            gPhaseActsArts.add(( TOOL[item], ONT.activityTool, ACT[row.ActivityIdentifier] )),\n",
        "            ) for item in row.ToolsList ],\n",
        "        gPhaseActsArts.add((\n",
        "            ACT[row.ActivityIdentifier], ONT.phaseActivity, PHASE[cleanCamel(row.Phase)]\n",
        "        )),\n",
        "        gPhaseActsArts.add((\n",
        "            PHASE[cleanCamel(row.Phase)], ONT.phaseActivity, ACT[row.ActivityIdentifier]\n",
        "        )),\n",
        "        gPhaseActsArts.add(( ACT[row.ActivityIdentifier] , SKOS.editorialNote, Literal(\"Unused Inputs text::\"+row.InputsTextRemainder))) if any(letter.isalpha() for letter in row.InputsTextRemainder) else None,\n",
        "        gPhaseActsArts.add(( ACT[row.ActivityIdentifier] , SKOS.editorialNote, Literal(\"Unused Outputs text::\"+row.OutputsTextRemainder))) if any(letter.isalpha() for letter in row.OutputsTextRemainder) else None,\n",
        "        gPhaseActsArts.add(( ACT[row.ActivityIdentifier] , SKOS.editorialNote, Literal(\"Unused Tools text::\"+row.ToolsTextRemainder))) if any(letter.isalpha() for letter in row.ToolsTextRemainder) else None,\n",
        "    )\n",
        "    , axis='columns' )\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUFXAU5ei0f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "gTopLevel.serialize(format=\"turtle\",destination=\"gen/topLevel.ttl\")\n",
        "gPhases.serialize(format=\"turtle\",destination=\"gen/phases.ttl\")\n",
        "gToolsArts.serialize(format=\"turtle\",destination=\"gen/toolsArts.ttl\")\n",
        "gPhaseActsArts.serialize(format=\"turtle\",destination=\"gen/phaseActsArts.ttl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrGpohrZrze3"
      },
      "source": [
        "## Publish the combined generated graph contributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_gDO5u58f67"
      },
      "outputs": [],
      "source": [
        "# publish combined graph\n",
        "# simply a case of parsing generated source graphs into the same graph\n",
        "\n",
        "gCombined = Graph()\n",
        "gCombined.add((BNode(), RDFS.label, Literal(\"Script Version: \" + str(scriptRevision))) )\n",
        "import glob\n",
        "for file in glob.glob(\"gen/*.ttl\"):\n",
        "    gCombined.parse(file)\n",
        "gCombined.serialize(format=\"turtle\",destination=\"publish/nodehenge.org/inst.ttl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Z4n_MPsEZn"
      },
      "source": [
        "## Some commented-out RDF exploration tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIe-ba3Zi0f4"
      },
      "outputs": [],
      "source": [
        "# some commented-out RDF exploration tests\n",
        "%%script false --no-raise-error\n",
        "\n",
        "# ONT = Namespace(\"http://nodehenge.org/ont#\")\n",
        "# INST = Namespace(\"http://nodehenge.org/inst#\")\n",
        "# PHASE = Namespace(\"http://nodehenge.org/inst/phase#\")\n",
        "# TOOL = Namespace(\"http://nodehenge.org/inst/tool#\")\n",
        "# ACT = Namespace(\"http://nodehenge.org/inst/activity#\")\n",
        "# ART = Namespace(\"http://nodehenge.org/inst/artifact#\")\n",
        "context = {\"@ont\": \"http://nodehenge.org/ont#\",\n",
        "           \"@inst\": \"http://nodehenge.org/inst#\",\n",
        "           \"@phase\": \"http://nodehenge.org/inst/phase#\",\n",
        "           \"@tool\": \"http://nodehenge.org/inst/tool#\",\n",
        "           \"@act\": \"http://nodehenge.org/inst/activity#\",\n",
        "           \"@artifact\": \"http://nodehenge.org/inst/artifact#\",\n",
        "           \"@skos\" :  \"http://www.w3.org/2004/02/skos/core#\",\n",
        "           \"@language\": \"en\"}\n",
        "#print(g.serialize(format=\"json-ld\", context=context ))  # example with manually constructed @context\n",
        "jsontxt=(g.serialize(format=\"json-ld\", auto_compact=True))  #auto_compact create @context entries\n",
        "jsonobj = json.loads(jsontxt)\n",
        "json.dumps(jsonobj, separators=(',', ':')) # minified output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lAHTcdMi0f5"
      },
      "outputs": [],
      "source": [
        "# some commented-out RDF exploration tests\n",
        "%%script false --no-raise-error\n",
        "\n",
        "g.add((\n",
        "    URIRef(\"#nick\"),\n",
        "    SKOS.prefLabel,\n",
        "    Literal(\"Nick\") #, datatype=XSD.string)\n",
        "    )\n",
        ")\n",
        "g.add((\n",
        "    URIRef(\"#bob\"),\n",
        "    SKOS.prefLabel,\n",
        "    Literal(\"Bob\") #, datatype=XSD.string)\n",
        "    )\n",
        ")\n",
        "\n",
        "print(g.serialize(format=\"turtle\"))\n",
        "\n",
        "my_query = \"\"\"\n",
        "SELECT DISTINCT ?a ?b\n",
        "WHERE {\n",
        "    ?a skos:prefLabel \"Nick\" .\n",
        "}\"\"\"\n",
        "\n",
        "qres = g.query(my_query)\n",
        "for row in qres:\n",
        "    print(f\"{row.a} \")\n",
        "\n",
        "bob=URIRef(\"#bob\")\n",
        "print(g.value(bob,SKOS.prefLabel))\n",
        "#```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wh9D_DWi0f6"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "\n",
        "g.add( (PHASE.plan, SKOS.prefLabel, Literal(\"Plan\")))\n",
        "print(  PHASE.plan )\n",
        "print( g.value( PHASE.plan, SKOS.prefLabel ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TA2vm1Gi0f7"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "\n",
        "phaseID = \"pha+--=sfgsdfg   \\n se13\"\n",
        "phaseID2 = \"phase13432\"\n",
        "g.remove( (PHASE[cleanCamel(phaseID)], None, None) )  #dict notation as alternative to explicit value and dot notation\n",
        "g.add( (PHASE[cleanCamel(phaseID)], SKOS.related, PHASE[phaseID2]))\n",
        "print( g.value( PHASE[cleanCamel(phaseID)], SKOS.related ) )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
